<!DOCTYPE html>
<html>
    <title>DMfD</title>

    <meta charset="UTF-8">
    <meta property="og:title" content=DMfD>
    <meta property="og:description" content="Salhotra et al. Learning Deformable Object Manipulation from Demonstrations">
    <meta property="og:url" content="">
    <meta property="og:image" content="">
    <meta property="og:type" content="website">
    <meta name="viewport" content="width=device-width, initial-scale=1 minimum-scale=1.0">

    <link rel="icon" type="image/png" href="img/favicon.ico">
    <link rel="stylesheet" href="https://www.w3schools.com/w3css/4/w3.css">
    <link href="https://fonts.googleapis.com/css?family=Roboto:100, 100i,300,400,500,700,900" rel="stylesheet">
    <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.8.1/css/all.css" integrity="sha384-50oBUHEmvpQ+1lW4y57PTFmhCaXp0ML5d60M1M7uH2+nqUivzIebhndOJK28anvf" crossorigin="anonymous">

    <!-- Showdown -->
    <script src=" https://cdnjs.cloudflare.com/ajax/libs/showdown/1.9.0/showdown.min.js"></script>
    <script src="js/figure-extension.js"></script>

    <!-- jQuery -->
    <script src="https://code.jquery.com/jquery-3.3.1.min.js" integrity="sha256-FgpCb/KJQlLNfOu91ta32o/NMZxltwRo8QtmkMRdAu8=" crossorigin="anonymous"></script>

    <!-- WAVE -->
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/materialize/1.0.0/css/materialize.min.css">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/materialize/1.0.0/js/materialize.min.js"></script>

    <!-- Slick -->
    <link rel="stylesheet" type="text/css" href="//cdn.jsdelivr.net/npm/slick-carousel@1.8.1/slick/slick.css"/>
    <link rel="stylesheet" type="text/css" href="//cdn.jsdelivr.net/npm/slick-carousel@1.8.1/slick/slick-theme.css"/>
    <script type="text/javascript" src="//cdn.jsdelivr.net/npm/slick-carousel@1.8.1/slick/slick.min.js"></script>

    <link rel="stylesheet" href="theme.css">

    <script>
        const classMap = {
            ul: 'browser-default'
        }

        const bindings = Object.keys(classMap)
        .map(key => ({
            type: 'output',
            regex: new RegExp(`<${key}(.*)>`, 'g'),
            replace: `<${key} class="${classMap[key]}" $1>`
        }));

        const converter = new showdown.Converter({
            extensions: [bindings, 'figure']
        });
        converter.setOption('parseImgDimensions', true);
        converter.setOption('tables', true);
        converter.setFlavor('github');

        $("#markdown-body").ready(() => {
            $.get( "content.md", (data) => {
                const content_html = converter.makeHtml(data);
                $("#markdown-body").html(content_html);
            });
        });

    </script>

    <body>
        <!-- Header -->
        <!-- Wide screen -->
        <header class="hd-container w3-container hide-narrow content-center">
            <div class="w3-cell-row" style="width: 90%; margin: auto; max-width: 1600px; margin-top: 80px; margin-bottom: 40px">
                <div class="w3-container w3-cell w3-cell-middle">
                    <div class="title">Learning Deformable Object Manipulation from Demonstrations</div>
                    <!-- Author -->
                <div class="w3-row-padding">
                    <div class="authorship-container">
                        <ul class="horizontal-list">
                            <li><a href="https://www.gautamsalhotra.com" target="_blank"><i class="far fa-user"></i> Gautam Salhotra<sup>*</sup></a></li>
                            <li><a href="https://arthurliu.netlify.app" target="_blank"><i class="far fa-user"></i> I-Chun Arthur Liu<sup>*</sup></a></li>
                            <li><a href="https://doku88.github.io/website.github.io/" target="_blank"><i class="far fa-user"></i> Marcus Dominguez-Kuhne</a></li>
                            <li><a href="http://robotics.usc.edu/~gaurav" target="_blank"><i class="far fa-user"></i> Gaurav S. Sukhatme </a></li>
                        </ul>
                        <span class="school"><a href="https://robotics.usc.edu/resl/" target="_blank"><i class="fas fa-university"></i> Robotics Embedded Systems Laboratory (RESL), USC<sup>2</sup> </a></span>
                    </div>
                    <div class="w3-card-4 w3-round-large furniture-grid" style="width: 80%; max-width: 700px">
                            <img width="100%" height="100%" src="img/Sim2Real_CFDUnpinned.png">
                    </div>

                    </div>
                    <div class="excerpt w3-padding-16" style="width: 80%; max-width: 700px; margin: auto;">
                        We present a novel Learning from Demonstration (LfD) method, Deformable Manipulation from Demonstrations (DMfD), to solve deformable manipulation tasks using states or images as inputs, given expert demonstrations. Our method uses demonstrations in three different ways, and balances the trade-off between exploring the environment online and using guidance from experts to explore high dimensional spaces effectively. We test DMfD on a set of representative manipulation tasks for a 1-dimensional rope and a 2-dimensional cloth from the SoftGym suite of tasks, each with state and image observations. Our method exceeds baseline performance by up to 12.9% for state-based tasks and up to 33.44% on image-based tasks, with comparable or better robustness to randomness. Additionally, we create two challenging environments for folding a 2D cloth using image-based observations, and set a performance benchmark for them. We deploy DMfD on a real robot with a minimal loss in normalized performance during real-world execution compared to simulation (~6%).
                    </div>
                </div>
            </div>
        </header>

        <!-- Narrow screen -->
        <header class="hd-container w3-container hide-wide">
            <div class="w3-row-padding w3-center w3-padding-24">
                <span class="title">Learning Deformable Object Manipulation from Demonstrations</span>
            </div>
            <div class="w3-row-padding">
                <!-- Author -->
                <div class="authorship-container">
                    <ul class="horizontal-list">
                        <li><a href="https://www.gautamsalhotra.com" target="_blank"><i class="far fa-user"></i> Gautam Salhotra<sup>*</sup></a></li>
                        <li><a href="https://arthurliu.netlify.app" target="_blank"><i class="far fa-user"></i> I-Chun Arthur Liu<sup>*</sup></a></li>
                        <li><a href="https://doku88.github.io/website.github.io/" target="_blank"><i class="far fa-user"></i> Marcus Dominguez-Kuhne</a></li>
                        <li><a href="http://robotics.usc.edu/~gaurav" target="_blank"><i class="far fa-user"></i> Gaurav S. Sukhatme </a></li>
                    </ul>
                    <span class="school"><a href="https://robotics.usc.edu/resl/" target="_blank"><i class="fas fa-university"></i> Robotics Embedded Systems Laboratory (RESL), USC</a></span>
                </div>

            </div>
            <div class="w3-row-padding w3-center w3-padding-16">
                <div class="w3-card-4 w3-round-large furniture-grid" style="width: 100%; max-width: 800px">
                        <img width="100%" height="100%" src="img/Sim2Real_CFDUnpinned.png">
                </div>
            </div>
            <div class="w3-row-padding"><hr></div>
            <div class="w3-row-padding w3-padding-16">
                <div class="excerpt">
                    Learning complex manipulation tasks in realistic, obstructed environments is a challenging problem due to hard exploration in the presence of obstacles and high-dimensional visual observations. Prior work tackles the exploration problem by integrating motion planning and reinforcement learning. However, the motion planner augmented policy requires access to state information, which is often not available in the real-world settings. To this end, we propose to distill the state-based motion planner augmented policy to a visual control policy via (1) visual behavioral cloning to remove the motion planner dependency along with its jittery motion, and (2) vision-based reinforcement learning with the guidance of the smoothed trajectories from the behavioral cloning agent. We validate our proposed approach on three manipulation tasks in obstructed environments and show its high sample-efficiency, outperforming state-of-the-art algorithms for visual policy learning.
                </div>
            </div>
        </header>

        <!-- Main Body -->
        <div class="main-body">
            <div class="w3-container">
                <div class="w3-content" style="max-width:1000px;">
                    <!-- Links -->
                    <div class="link-container">
                        <ul class="horizontal-list">
                            <!-- <li><button class="w3-button waves-effect waves-light w3-card-4 grey lighten-2 w3-round-large"><i class="fas fa-file-alt"></i> <a href="http://TO.DO" target="_blank"> Paper </a></button></li> -->
                            <li><button class="w3-button waves-effect waves-light w3-card-4 grey lighten-2 w3-round-large"><i class="fas fa-code"></i> <a href="https://github.com/uscresl/dmfd" target="_blank"> Code </a></button></li>
                            <!-- <li><button class="w3-button waves-effect waves-light w3-card-4 grey lighten-2 w3-round-large"><i class="fas fa-graduation-cap"></i> <a href="https://clvrai.github.io/mopa-rl/" target="_blank"> Prior Work: MoPA-RL </a></button></li> -->
                        </ul>
                    </div>
                    <!-- Markdown Body -->
                    <div id="markdown-body"></div>
                </div>
            </div>
        </div>

        <!-- Footer -->
        <footer class="w3-center w3-light-grey w3-padding-32 w3-small">
            <p style="color: grey">We thank our colleagues from the RESL for the valuable discussions that considerably assisted the research. <br>&copy; Copyright 2022, RESL, USC.</p>
        </footer>

    </body>
</html>
